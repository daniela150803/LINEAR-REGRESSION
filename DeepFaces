{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniela150803/LINEAR-REGRESSION/blob/main/DeepFaces\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Fijar semilla para reproducibilidad\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Verificar disponibilidad de GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(\"GPU detectada\")\n",
        "else:\n",
        "    print(\"No se detectó GPU\")\n",
        "\n",
        "# =============================================================================\n",
        "# Dataset: Usando tf.data para mayor eficiencia\n",
        "# =============================================================================\n",
        "# Directorio del dataset (verifica que la ruta sea correcta)\n",
        "data_dir = \"/root/.cache/kagglehub/datasets/kshitizbhargava/deepfake-face-images/versions/1/Final Dataset\"\n",
        "print(\"Contenido de Final Dataset:\", os.listdir(data_dir))\n",
        "\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "batch_size = 24\n",
        "\n",
        "# Crear datasets de entrenamiento y validación\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=(img_height, img_width),\n",
        "    label_mode=\"categorical\",\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    image_size=(img_height, img_width),\n",
        "    label_mode=\"categorical\",\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(\"Clases:\", class_names)\n",
        "\n",
        "# Capa de data augmentation (se ejecuta en GPU)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1)\n",
        "])\n",
        "\n",
        "# Aplicar cache y prefetch para acelerar el pipeline\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Calcular pesos de clase a partir de los labels (para compensar desbalance)\n",
        "import numpy as np\n",
        "y_train = np.concatenate([y for x, y in train_ds], axis=0)\n",
        "class_totals = np.sum(y_train, axis=0)\n",
        "total_samples = np.sum(class_totals)\n",
        "class_weights = {i: total_samples/(len(class_totals)*class_totals[i]) for i in range(len(class_totals))}\n",
        "print(\"Pesos de clase:\", class_weights)\n",
        "\n",
        "# =============================================================================\n",
        "# Definición de Capas Personalizadas\n",
        "# =============================================================================\n",
        "\n",
        "class FrequencyAnalyzer(layers.Layer):\n",
        "    \"\"\"Capa que analiza anomalías en el dominio de la frecuencia.\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(FrequencyAnalyzer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')\n",
        "        self.conv2 = layers.Conv2D(64, (5, 5), activation='relu', padding='same')\n",
        "        self.conv3 = layers.Conv2D(32, (7, 7), activation='relu', padding='same')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "        self.bn3 = layers.BatchNormalization()\n",
        "        super(FrequencyAnalyzer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        inputs_f32 = tf.cast(inputs, tf.float32)\n",
        "        weights = tf.constant([0.299, 0.587, 0.114], dtype=tf.float32)\n",
        "        gray = tf.reduce_sum(inputs_f32 * weights, axis=-1, keepdims=True)\n",
        "        fft_gray = tf.signal.fft2d(tf.cast(tf.squeeze(gray, axis=-1), tf.complex64))\n",
        "        fft_shifted_gray = tf.signal.fftshift(fft_gray)\n",
        "        magnitude_gray = tf.math.log(tf.abs(fft_shifted_gray) + 1e-6)\n",
        "        magnitude_gray = tf.expand_dims(magnitude_gray, axis=-1)\n",
        "        x1 = self.conv1(magnitude_gray)\n",
        "        x1 = self.bn1(x1, training=training)\n",
        "        x2 = self.conv2(magnitude_gray)\n",
        "        x2 = self.bn2(x2, training=training)\n",
        "        x3 = self.conv3(magnitude_gray)\n",
        "        x3 = self.bn3(x3, training=training)\n",
        "        x = tf.concat([x1, x2, x3], axis=-1)\n",
        "        return x\n",
        "\n",
        "class NoisePatternAnalyzer(layers.Layer):\n",
        "    \"\"\"Analiza patrones de ruido para detectar inconsistencias en las imágenes.\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(NoisePatternAnalyzer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')\n",
        "        self.conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "        super(NoisePatternAnalyzer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        inputs_f32 = tf.cast(inputs, tf.float32)\n",
        "        weights = tf.constant([0.299, 0.587, 0.114], dtype=tf.float32)\n",
        "        gray = tf.reduce_sum(inputs_f32 * weights, axis=-1, keepdims=True)\n",
        "        # Suavizado simple para extraer ruido\n",
        "        blur = tf.nn.avg_pool2d(gray, ksize=3, strides=1, padding='SAME')\n",
        "        noise = gray - blur\n",
        "        noise_mean = tf.reduce_mean(noise)\n",
        "        noise_std = tf.math.reduce_std(noise) + 1e-6\n",
        "        noise_normalized = (noise - noise_mean) / noise_std\n",
        "        x = self.conv1(noise_normalized)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "        return x\n",
        "\n",
        "class SpatialAttention(layers.Layer):\n",
        "    \"\"\"Módulo de atención espacial para enfocarse en áreas sospechosas.\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(SpatialAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.conv1 = layers.Conv2D(64, kernel_size=7, padding='same', activation='relu')\n",
        "        self.conv2 = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')\n",
        "        super(SpatialAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        inputs = tf.cast(inputs, tf.float32)\n",
        "        avg_pool = tf.reduce_mean(inputs, axis=3, keepdims=True)\n",
        "        max_pool = tf.reduce_max(inputs, axis=3, keepdims=True)\n",
        "        concat = tf.concat([avg_pool, max_pool], axis=3)\n",
        "        x = self.conv1(concat)\n",
        "        x = self.conv2(x)\n",
        "        return x * inputs\n",
        "\n",
        "# =============================================================================\n",
        "# Modelo Mejorado\n",
        "# =============================================================================\n",
        "\n",
        "def EnhancedDeepfakeDetector(input_shape=(224, 224, 3), use_mixed_precision=True):\n",
        "    # Activar precisión mixta si hay GPU y se solicita\n",
        "    if use_mixed_precision and gpus:\n",
        "        policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "        tf.keras.mixed_precision.set_global_policy(policy)\n",
        "        print(\"Precisión mixta activada\")\n",
        "    else:\n",
        "        tf.keras.mixed_precision.set_global_policy('float32')\n",
        "        print(\"Usando precisión float32\")\n",
        "\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Aplicar data augmentation\n",
        "    x_aug = data_augmentation(inputs)\n",
        "    x = x_aug  # El dataset ya maneja el escalado (o puedes aplicar una capa Rescaling si es necesario)\n",
        "\n",
        "    # Rama 1: Extracción de características con EfficientNetB0\n",
        "    base_model = EfficientNetB0(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_tensor=x,\n",
        "        pooling=None\n",
        "    )\n",
        "    # Congelar las primeras 50 capas para acelerar el entrenamiento\n",
        "    for layer in base_model.layers[:50]:\n",
        "        layer.trainable = False\n",
        "    activations = []\n",
        "    target_layers = ['block1a_project_bn', 'block3a_expand_activation', 'block5c_add', 'block7a_project_bn']\n",
        "    for layer_name in target_layers:\n",
        "        activation = base_model.get_layer(layer_name).output\n",
        "        activations.append(activation)\n",
        "\n",
        "    # Rama 2: Análisis de frecuencia\n",
        "    x_freq = FrequencyAnalyzer()(inputs)\n",
        "    x_freq = layers.MaxPooling2D((2, 2))(x_freq)\n",
        "    x_freq = SpatialAttention()(x_freq)\n",
        "\n",
        "    # Rama 3: Análisis de patrones de ruido\n",
        "    x_noise = NoisePatternAnalyzer()(inputs)\n",
        "    x_noise = layers.MaxPooling2D((2, 2))(x_noise)\n",
        "\n",
        "    processed_features = []\n",
        "    # Procesar activaciones del EfficientNet\n",
        "    for i, activation in enumerate(activations):\n",
        "        x_act = layers.Conv2D(64, (1, 1), padding='same')(activation)\n",
        "        x_act = layers.BatchNormalization()(x_act)\n",
        "        if i == len(activations) - 1:\n",
        "            x_act = SpatialAttention()(x_act)\n",
        "        x_act = layers.GlobalAveragePooling2D()(x_act)\n",
        "        processed_features.append(x_act)\n",
        "\n",
        "    x_freq = layers.GlobalAveragePooling2D()(x_freq)\n",
        "    x_freq = layers.Dense(128, activation='relu')(x_freq)\n",
        "    processed_features.append(x_freq)\n",
        "\n",
        "    x_noise = layers.GlobalAveragePooling2D()(x_noise)\n",
        "    x_noise = layers.Dense(64, activation='relu')(x_noise)\n",
        "    processed_features.append(x_noise)\n",
        "\n",
        "    x = layers.Concatenate()(processed_features)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    outputs = layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# =============================================================================\n",
        "# Compilación y Entrenamiento\n",
        "# =============================================================================\n",
        "\n",
        "initial_lr = 1e-4\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_lr,\n",
        "    decay_steps=500,\n",
        "    decay_rate=0.9,\n",
        "    staircase=True\n",
        ")\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "modelo = EnhancedDeepfakeDetector(use_mixed_precision=True)\n",
        "modelo.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['categorical_accuracy', tf.keras.metrics.AUC()]\n",
        ")\n",
        "\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr_cb = callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "epochs = 15  # Menos épocas para pruebas rápidas\n",
        "\n",
        "history = modelo.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping, reduce_lr_cb],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "modelo.save('deepfake_detector_enhanced.h5')\n",
        "\n",
        "# =============================================================================\n",
        "# Visualización de Métricas\n",
        "# =============================================================================\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['categorical_accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_categorical_accuracy'], label='Val Accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_metrics.png')\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# Función de Predicción Mejorada\n",
        "# =============================================================================\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def predict_image(img_path, model, class_names):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x_original = x.copy()\n",
        "    x = np.expand_dims(x, axis=0) / 255.0\n",
        "    preds = model.predict(x)\n",
        "    confidence = np.max(preds) * 100\n",
        "    result_idx = np.argmax(preds, axis=-1)[0]\n",
        "    result_label = class_names[result_idx]\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(x_original.astype(np.uint8))\n",
        "    plt.title(f'Predicción: {result_label.upper()}\\nConfianza: {confidence:.2f}%')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    img_gray = cv2.cvtColor(x_original.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
        "    edges = cv2.Canny(img_gray, 100, 200)\n",
        "    edges = cv2.GaussianBlur(edges, (5, 5), 0)\n",
        "    plt.imshow(edges, cmap='hot')\n",
        "    plt.title('Áreas potencialmente manipuladas')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('prediction_result.png')\n",
        "    plt.show()\n",
        "\n",
        "    return result_label, confidence\n",
        "\n",
        "# Ruta de la imagen para predicción (verifica que el archivo exista)\n",
        "img_path = '/content/Real.jpg'\n",
        "result_label, confidence = predict_image(img_path, modelo, class_names)\n",
        "print(f\"Clase predicha: {result_label} con {confidence:.2f}% de confianza\")\n"
      ],
      "metadata": {
        "id": "av-q86vsqp0a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}